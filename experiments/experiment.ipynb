{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22c3013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 实验 Notebook - 代码块 1 ====\n",
    "# 公共导入 + 实验 1：静态方向 + 长时间窗（T=800ms）\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 保证在项目根目录下运行 Notebook\n",
    "# 目录结构中应该有 encoding/ 和 decoding/ 这些包\n",
    "from encoding.dataset_builder import generate_direction_encoding_dataset\n",
    "from decoding.linear_decoder import train_and_eval_linear\n",
    "from decoding.rate_decoder_mlp import train_rate_mlp\n",
    "from decoding.snn_decoder import train_snn_decoder\n",
    "\n",
    "# 让图更好看一点\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "plt.rcParams[\"font.size\"] = 11\n",
    "\n",
    "\n",
    "# ===================== 实验 1：静态方向 + 长时间窗 =====================\n",
    "\n",
    "def run_experiment_static_long_T(\n",
    "    T_ms=800.0,\n",
    "    n_neurons=40,\n",
    "    trials_per_dir=100,\n",
    "    seed=0,\n",
    "    save_tmp=True,\n",
    "    tmp_path=\"exp1_static_T800.npz\",\n",
    "    n_epochs_mlp=40,\n",
    "    n_epochs_snn=40,\n",
    "):\n",
    "    \"\"\"\n",
    "    实验 1：静态 8 方向 + 长时间窗（T=800ms）\n",
    "    - Linear / MLP：输入 spike count\n",
    "    - SNN：输入完整 spike train\n",
    "    \"\"\"\n",
    "\n",
    "    directions = np.arange(0, 360, 45)  # 8 个方向\n",
    "    print(f\"=== Experiment 1: Static directions, T={T_ms} ms, N={n_neurons} ===\")\n",
    "\n",
    "    # 1) 生成数据（中等噪声）\n",
    "    dataset = generate_direction_encoding_dataset(\n",
    "        directions_deg=directions,\n",
    "        n_neurons=n_neurons,\n",
    "        trials_per_dir=trials_per_dir,\n",
    "        T=T_ms,\n",
    "        dt=1.0,\n",
    "        r_baseline=8.0,\n",
    "        r_max_mean=25.0,\n",
    "        r_max_std=6.0,\n",
    "        tuning_sigma_deg=50.0,\n",
    "        jitter_pref_deg=7.0,\n",
    "        gain_sigma=0.25,\n",
    "        shared_std=3.0,\n",
    "        indep_std=2.0,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    spikes = dataset[\"spikes\"]\n",
    "    labels = dataset[\"labels\"]\n",
    "    directions_deg = dataset[\"directions_deg\"]\n",
    "\n",
    "    print(\"Dataset shape (spikes):\", spikes.shape)\n",
    "\n",
    "    # 2) 保存临时数据集，兼容 decoding 模块\n",
    "    if save_tmp:\n",
    "        np.savez(\n",
    "            tmp_path,\n",
    "            spikes=spikes,\n",
    "            labels=labels,\n",
    "            directions_deg=directions_deg,\n",
    "            meta=np.array([dataset[\"meta\"]], dtype=object),\n",
    "        )\n",
    "        print(\"Saved temp dataset to:\", tmp_path)\n",
    "        dataset_path = tmp_path\n",
    "    else:\n",
    "        # 如果不保存，就直接写一个内存 npz 的替代接口（这里简单起见直接保存）\n",
    "        raise NotImplementedError(\"建议保存成 npz 再用解码器\")\n",
    "\n",
    "    # 3) Linear 解码\n",
    "    print(\"\\n[Experiment 1] Linear decoder (rate)\")\n",
    "    _, (train_acc_lin, test_acc_lin) = train_and_eval_linear(\n",
    "        dataset_path=dataset_path,\n",
    "        test_size=0.2,\n",
    "        random_state=0,\n",
    "    )\n",
    "\n",
    "    # 4) MLP 解码\n",
    "    print(\"\\n[Experiment 1] MLP decoder (rate)\")\n",
    "    _, (test_acc_mlp, _) = train_rate_mlp(\n",
    "        dataset_path=dataset_path,\n",
    "        test_size=0.2,\n",
    "        random_state=0,\n",
    "        n_epochs=n_epochs_mlp,\n",
    "    )\n",
    "\n",
    "    # 5) SNN 解码\n",
    "    print(\"\\n[Experiment 1] SNN decoder (spike train)\")\n",
    "    _, (test_acc_snn, _) = train_snn_decoder(\n",
    "        dataset_path=dataset_path,\n",
    "        test_size=0.2,\n",
    "        random_state=0,\n",
    "        n_epochs=n_epochs_snn,\n",
    "    )\n",
    "\n",
    "    # 6) 小总结条形图\n",
    "    methods = [\"Linear\", \"MLP (rate)\", \"SNN (spike)\"]\n",
    "    accs = [test_acc_lin, test_acc_mlp, test_acc_snn]\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.bar(methods, accs)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.ylabel(\"Test accuracy\")\n",
    "    plt.title(f\"Experiment 1: Static directions, T={T_ms} ms\")\n",
    "    for i, a in enumerate(accs):\n",
    "        plt.text(i, a + 0.02, f\"{a:.2f}\", ha=\"center\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        \"test_acc_lin\": test_acc_lin,\n",
    "        \"test_acc_mlp\": test_acc_mlp,\n",
    "        \"test_acc_snn\": test_acc_snn,\n",
    "    }\n",
    "\n",
    "\n",
    "# 直接运行实验 1\n",
    "results_exp1 = run_experiment_static_long_T()\n",
    "results_exp1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efe8b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 实验 Notebook - 代码块 2 ====\n",
    "# 实验 2：短时间窗 + 方向快速变化（两段不同方向，标签为后半段方向）\n",
    "\n",
    "from encoding.tuning import (\n",
    "    generate_preferred_directions,\n",
    "    sample_r_max,\n",
    "    direction_tuning_gaussian,\n",
    ")\n",
    "from encoding.poisson_spike import poisson_population_spikes\n",
    "\n",
    "\n",
    "def generate_two_segment_direction_dataset(\n",
    "    directions_deg,\n",
    "    n_neurons=40,\n",
    "    trials_total=800,\n",
    "    T1=100.0,\n",
    "    T2=100.0,\n",
    "    dt=1.0,\n",
    "    r_baseline=8.0,\n",
    "    r_max_mean=25.0,\n",
    "    r_max_std=6.0,\n",
    "    tuning_sigma_deg=50.0,\n",
    "    jitter_pref_deg=7.0,\n",
    "    gain_sigma=0.25,\n",
    "    shared_std=3.0,\n",
    "    indep_std=2.0,\n",
    "    seed=123,\n",
    "):\n",
    "    \"\"\"\n",
    "    生成“前后两段不同方向”的时间相关数据集。\n",
    "\n",
    "    每个 trial：\n",
    "    - 前 T1 ms：方向 theta1\n",
    "    - 后 T2 ms：方向 theta2\n",
    "    - 标签：theta2 对应的方向类别 idx\n",
    "\n",
    "    返回：\n",
    "    - spikes : (n_examples, T_steps_total, n_neurons)\n",
    "    - labels : (n_examples,)\n",
    "    - directions_deg : (n_dirs,)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    directions_deg = np.asarray(directions_deg)\n",
    "    n_dirs = directions_deg.shape[0]\n",
    "    T1_steps = int(T1 / dt)\n",
    "    T2_steps = int(T2 / dt)\n",
    "    T_steps_total = T1_steps + T2_steps\n",
    "\n",
    "    # Population 参数\n",
    "    theta_prefs = generate_preferred_directions(\n",
    "        n_neurons=n_neurons,\n",
    "        jitter_deg=jitter_pref_deg,\n",
    "        seed=rng.integers(1_000_000_000),\n",
    "    )\n",
    "    r_max = sample_r_max(\n",
    "        n_neurons=n_neurons,\n",
    "        r_max_mean=r_max_mean,\n",
    "        r_max_std=r_max_std,\n",
    "        min_rate=1.0,\n",
    "        max_rate=None,\n",
    "        seed=rng.integers(1_000_000_000),\n",
    "    )\n",
    "\n",
    "    # 预先算好 tuning\n",
    "    base_rates_all = direction_tuning_gaussian(\n",
    "        theta_stim_deg=directions_deg,\n",
    "        theta_pref_deg=theta_prefs,\n",
    "        r_baseline=r_baseline,\n",
    "        r_max=r_max,\n",
    "        sigma_deg=tuning_sigma_deg,\n",
    "    )  # (n_dirs, n_neurons)\n",
    "\n",
    "    spikes = np.zeros((trials_total, T_steps_total, n_neurons), dtype=np.uint8)\n",
    "    labels = np.zeros(trials_total, dtype=np.int64)\n",
    "    theta1_idx_all = rng.integers(low=0, high=n_dirs, size=trials_total)\n",
    "    theta2_idx_all = rng.integers(low=0, high=n_dirs, size=trials_total)\n",
    "\n",
    "    for i in range(trials_total):\n",
    "        d1_idx = theta1_idx_all[i]\n",
    "        d2_idx = theta2_idx_all[i]\n",
    "\n",
    "        rates1 = base_rates_all[d1_idx].copy()\n",
    "        rates2 = base_rates_all[d2_idx].copy()\n",
    "\n",
    "        # trial-by-trial 噪声我们分别对两个段加（也可以只在整个 trial 上加一次）\n",
    "        def apply_noise(rates_segment):\n",
    "            rates = rates_segment.copy()\n",
    "            if gain_sigma > 0.0:\n",
    "                gain = rng.lognormal(mean=0.0, sigma=gain_sigma)\n",
    "                rates *= gain\n",
    "            if shared_std > 0.0:\n",
    "                rates += rng.normal(0.0, shared_std)\n",
    "            if indep_std > 0.0:\n",
    "                rates += rng.normal(0.0, indep_std, size=n_neurons)\n",
    "            return np.clip(rates, 0.0, None)\n",
    "\n",
    "        rates1_noisy = apply_noise(rates1)\n",
    "        rates2_noisy = apply_noise(rates2)\n",
    "\n",
    "        spikes1 = poisson_population_spikes(\n",
    "            rates_hz=rates1_noisy,\n",
    "            T=T1,\n",
    "            dt=dt,\n",
    "            rng=rng,\n",
    "        )  # (T1_steps, n_neurons)\n",
    "        spikes2 = poisson_population_spikes(\n",
    "            rates_hz=rates2_noisy,\n",
    "            T=T2,\n",
    "            dt=dt,\n",
    "            rng=rng,\n",
    "        )  # (T2_steps, n_neurons)\n",
    "\n",
    "        spikes[i, :T1_steps] = spikes1\n",
    "        spikes[i, T1_steps:] = spikes2\n",
    "        labels[i] = d2_idx  # 标签 = 后半段方向\n",
    "\n",
    "    meta = {\n",
    "        \"T_total\": T1 + T2,\n",
    "        \"T1\": T1,\n",
    "        \"T2\": T2,\n",
    "        \"dt\": dt,\n",
    "        \"r_baseline\": r_baseline,\n",
    "        \"r_max_mean\": r_max_mean,\n",
    "        \"r_max_std\": r_max_std,\n",
    "        \"tuning_sigma_deg\": tuning_sigma_deg,\n",
    "        \"jitter_pref_deg\": jitter_pref_deg,\n",
    "        \"gain_sigma\": gain_sigma,\n",
    "        \"shared_std\": shared_std,\n",
    "        \"indep_std\": indep_std,\n",
    "        \"n_neurons\": n_neurons,\n",
    "        \"trials_total\": trials_total,\n",
    "        \"seed\": seed,\n",
    "        \"task\": \"decode_second_segment_direction\",\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"spikes\": spikes,\n",
    "        \"labels\": labels,\n",
    "        \"directions_deg\": directions_deg,\n",
    "        \"theta_prefs\": theta_prefs,\n",
    "        \"r_max\": r_max,\n",
    "        \"meta\": meta,\n",
    "    }\n",
    "\n",
    "\n",
    "def run_experiment_two_segment(\n",
    "    T1=100.0,\n",
    "    T2=100.0,\n",
    "    n_neurons=40,\n",
    "    trials_total=1600,\n",
    "    seed=1,\n",
    "    tmp_path=\"exp2_two_segment_T100_100.npz\",\n",
    "    n_epochs_mlp=40,\n",
    "    n_epochs_snn=40,\n",
    "):\n",
    "    \"\"\"\n",
    "    实验 2：短时间窗 + 方向快速变化（两段不同方向，标签为后半段方向）\n",
    "    \"\"\"\n",
    "\n",
    "    directions = np.arange(0, 360, 45)\n",
    "    print(\n",
    "        f\"=== Experiment 2: Two-segment stimulus, \"\n",
    "        f\"T1={T1} ms, T2={T2} ms, N={n_neurons} ===\"\n",
    "    )\n",
    "\n",
    "    dataset = generate_two_segment_direction_dataset(\n",
    "        directions_deg=directions,\n",
    "        n_neurons=n_neurons,\n",
    "        trials_total=trials_total,\n",
    "        T1=T1,\n",
    "        T2=T2,\n",
    "        dt=1.0,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    spikes = dataset[\"spikes\"]\n",
    "    labels = dataset[\"labels\"]\n",
    "    directions_deg = dataset[\"directions_deg\"]\n",
    "    print(\"Dataset shape (spikes):\", spikes.shape)\n",
    "\n",
    "    np.savez(\n",
    "        tmp_path,\n",
    "        spikes=spikes,\n",
    "        labels=labels,\n",
    "        directions_deg=directions_deg,\n",
    "        meta=np.array([dataset[\"meta\"]], dtype=object),\n",
    "    )\n",
    "    print(\"Saved temp dataset to:\", tmp_path)\n",
    "\n",
    "    # 1) Linear 解码（rate+whole-window）\n",
    "    print(\"\\n[Experiment 2] Linear decoder (whole-window rate)\")\n",
    "    _, (train_acc_lin, test_acc_lin) = train_and_eval_linear(\n",
    "        dataset_path=tmp_path,\n",
    "        test_size=0.2,\n",
    "        random_state=0,\n",
    "    )\n",
    "\n",
    "    # 2) MLP 解码\n",
    "    print(\"\\n[Experiment 2] MLP decoder (whole-window rate)\")\n",
    "    _, (test_acc_mlp, _) = train_rate_mlp(\n",
    "        dataset_path=tmp_path,\n",
    "        test_size=0.2,\n",
    "        random_state=0,\n",
    "        n_epochs=n_epochs_mlp,\n",
    "    )\n",
    "\n",
    "    # 3) SNN 解码（完整 spike train，能利用时间结构）\n",
    "    print(\"\\n[Experiment 2] SNN decoder (spike train, time-structure)\")\n",
    "    _, (test_acc_snn, _) = train_snn_decoder(\n",
    "        dataset_path=tmp_path,\n",
    "        test_size=0.2,\n",
    "        random_state=0,\n",
    "        n_epochs=n_epochs_snn,\n",
    "    )\n",
    "\n",
    "    methods = [\"Linear\", \"MLP (rate)\", \"SNN (spike)\"]\n",
    "    accs = [test_acc_lin, test_acc_mlp, test_acc_snn]\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.bar(methods, accs)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.ylabel(\"Test accuracy\")\n",
    "    plt.title(f\"Experiment 2: Two-segment task (label = θ₂)\")\n",
    "    for i, a in enumerate(accs):\n",
    "        plt.text(i, a + 0.02, f\"{a:.2f}\", ha=\"center\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        \"test_acc_lin\": test_acc_lin,\n",
    "        \"test_acc_mlp\": test_acc_mlp,\n",
    "        \"test_acc_snn\": test_acc_snn,\n",
    "    }\n",
    "\n",
    "\n",
    "# 直接运行实验 2\n",
    "results_exp2 = run_experiment_two_segment()\n",
    "results_exp2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5ab175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 实验 Notebook - 代码块 3 ====\n",
    "# 实验 3：population size / tuning width / 噪声强度 sweep\n",
    "\n",
    "def sweep_population_size(\n",
    "    N_list=(10, 20, 40, 80),\n",
    "    T_ms=400.0,\n",
    "    trials_per_dir=100,\n",
    "    base_seed=100,\n",
    "    n_epochs_mlp=30,\n",
    "    n_epochs_snn=30,\n",
    "):\n",
    "    directions = np.arange(0, 360, 45)\n",
    "    acc_lin, acc_mlp, acc_snn = [], [], []\n",
    "\n",
    "    for i, N in enumerate(N_list):\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"[Sweep N] N_neurons = {N}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        dataset = generate_direction_encoding_dataset(\n",
    "            directions_deg=directions,\n",
    "            n_neurons=N,\n",
    "            trials_per_dir=trials_per_dir,\n",
    "            T=T_ms,\n",
    "            dt=1.0,\n",
    "            r_baseline=8.0,\n",
    "            r_max_mean=25.0,\n",
    "            r_max_std=6.0,\n",
    "            tuning_sigma_deg=50.0,\n",
    "            jitter_pref_deg=7.0,\n",
    "            gain_sigma=0.25,\n",
    "            shared_std=3.0,\n",
    "            indep_std=2.0,\n",
    "            seed=base_seed + i,\n",
    "        )\n",
    "        spikes, labels, directions_deg = (\n",
    "            dataset[\"spikes\"],\n",
    "            dataset[\"labels\"],\n",
    "            dataset[\"directions_deg\"],\n",
    "        )\n",
    "        tmp_path = f\"tmp_sweep_N_{N}.npz\"\n",
    "        np.savez(\n",
    "            tmp_path,\n",
    "            spikes=spikes,\n",
    "            labels=labels,\n",
    "            directions_deg=directions_deg,\n",
    "            meta=np.array([dataset[\"meta\"]], dtype=object),\n",
    "        )\n",
    "\n",
    "        # Linear\n",
    "        _, (_, test_acc_lin) = train_and_eval_linear(\n",
    "            dataset_path=tmp_path,\n",
    "            test_size=0.2,\n",
    "            random_state=0,\n",
    "        )\n",
    "        acc_lin.append(test_acc_lin)\n",
    "\n",
    "        # MLP\n",
    "        _, (test_acc_mlp, _) = train_rate_mlp(\n",
    "            dataset_path=tmp_path,\n",
    "            test_size=0.2,\n",
    "            random_state=0,\n",
    "            n_epochs=n_epochs_mlp,\n",
    "        )\n",
    "        acc_mlp.append(test_acc_mlp)\n",
    "\n",
    "        # SNN\n",
    "        _, (test_acc_snn, _) = train_snn_decoder(\n",
    "            dataset_path=tmp_path,\n",
    "            test_size=0.2,\n",
    "            random_state=0,\n",
    "            n_epochs=n_epochs_snn,\n",
    "        )\n",
    "        acc_snn.append(test_acc_snn)\n",
    "\n",
    "        os.remove(tmp_path)\n",
    "\n",
    "    N_arr = np.array(N_list, dtype=int)\n",
    "    return N_arr, np.array(acc_lin), np.array(acc_mlp), np.array(acc_snn)\n",
    "\n",
    "\n",
    "def sweep_tuning_sigma(\n",
    "    sigma_list=(30.0, 45.0, 60.0),\n",
    "    T_ms=400.0,\n",
    "    n_neurons=40,\n",
    "    trials_per_dir=100,\n",
    "    base_seed=200,\n",
    "    n_epochs_mlp=30,\n",
    "    n_epochs_snn=30,\n",
    "):\n",
    "    directions = np.arange(0, 360, 45)\n",
    "    acc_lin, acc_mlp, acc_snn = [], [], []\n",
    "\n",
    "    for i, sigma in enumerate(sigma_list):\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"[Sweep sigma] sigma = {sigma} deg\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        dataset = generate_direction_encoding_dataset(\n",
    "            directions_deg=directions,\n",
    "            n_neurons=n_neurons,\n",
    "            trials_per_dir=trials_per_dir,\n",
    "            T=T_ms,\n",
    "            dt=1.0,\n",
    "            r_baseline=8.0,\n",
    "            r_max_mean=25.0,\n",
    "            r_max_std=6.0,\n",
    "            tuning_sigma_deg=sigma,\n",
    "            jitter_pref_deg=7.0,\n",
    "            gain_sigma=0.25,\n",
    "            shared_std=3.0,\n",
    "            indep_std=2.0,\n",
    "            seed=base_seed + i,\n",
    "        )\n",
    "        spikes, labels, directions_deg = (\n",
    "            dataset[\"spikes\"],\n",
    "            dataset[\"labels\"],\n",
    "            dataset[\"directions_deg\"],\n",
    "        )\n",
    "        tmp_path = f\"tmp_sweep_sigma_{int(sigma)}.npz\"\n",
    "        np.savez(\n",
    "            tmp_path,\n",
    "            spikes=spikes,\n",
    "            labels=labels,\n",
    "            directions_deg=directions_deg,\n",
    "            meta=np.array([dataset[\"meta\"]], dtype=object),\n",
    "        )\n",
    "\n",
    "        # Linear\n",
    "        _, (_, test_acc_lin) = train_and_eval_linear(\n",
    "            dataset_path=tmp_path,\n",
    "            test_size=0.2,\n",
    "            random_state=0,\n",
    "        )\n",
    "        acc_lin.append(test_acc_lin)\n",
    "\n",
    "        # MLP\n",
    "        _, (test_acc_mlp, _) = train_rate_mlp(\n",
    "            dataset_path=tmp_path,\n",
    "            test_size=0.2,\n",
    "            random_state=0,\n",
    "            n_epochs=n_epochs_mlp,\n",
    "        )\n",
    "        acc_mlp.append(test_acc_mlp)\n",
    "\n",
    "        # SNN\n",
    "        _, (test_acc_snn, _) = train_snn_decoder(\n",
    "            dataset_path=tmp_path,\n",
    "            test_size=0.2,\n",
    "            random_state=0,\n",
    "            n_epochs=n_epochs_snn,\n",
    "        )\n",
    "        acc_snn.append(test_acc_snn)\n",
    "\n",
    "        os.remove(tmp_path)\n",
    "\n",
    "    sigma_arr = np.array(sigma_list, dtype=float)\n",
    "    return sigma_arr, np.array(acc_lin), np.array(acc_mlp), np.array(acc_snn)\n",
    "\n",
    "\n",
    "def sweep_noise_level(\n",
    "    noise_levels=(0.0, 0.2, 0.4),\n",
    "    T_ms=400.0,\n",
    "    n_neurons=40,\n",
    "    trials_per_dir=100,\n",
    "    base_seed=300,\n",
    "    n_epochs_mlp=30,\n",
    "    n_epochs_snn=30,\n",
    "):\n",
    "    \"\"\"\n",
    "    用一个 noise_level 统一 scale 三种噪声：\n",
    "    gain_sigma = noise_level\n",
    "    shared_std = 3.0 * noise_level\n",
    "    indep_std  = 2.0 * noise_level\n",
    "    \"\"\"\n",
    "    directions = np.arange(0, 360, 45)\n",
    "    acc_lin, acc_mlp, acc_snn = [], [], []\n",
    "\n",
    "    for i, nl in enumerate(noise_levels):\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"[Sweep noise] noise_level = {nl}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        dataset = generate_direction_encoding_dataset(\n",
    "            directions_deg=directions,\n",
    "            n_neurons=n_neurons,\n",
    "            trials_per_dir=trials_per_dir,\n",
    "            T=T_ms,\n",
    "            dt=1.0,\n",
    "            r_baseline=8.0,\n",
    "            r_max_mean=25.0,\n",
    "            r_max_std=6.0,\n",
    "            tuning_sigma_deg=50.0,\n",
    "            jitter_pref_deg=7.0,\n",
    "            gain_sigma=nl,\n",
    "            shared_std=3.0 * nl,\n",
    "            indep_std=2.0 * nl,\n",
    "            seed=base_seed + i,\n",
    "        )\n",
    "        spikes, labels, directions_deg = (\n",
    "            dataset[\"spikes\"],\n",
    "            dataset[\"labels\"],\n",
    "            dataset[\"directions_deg\"],\n",
    "        )\n",
    "        tmp_path = f\"tmp_sweep_noise_{nl:.1f}.npz\"\n",
    "        np.savez(\n",
    "            tmp_path,\n",
    "            spikes=spikes,\n",
    "            labels=labels,\n",
    "            directions_deg=directions_deg,\n",
    "            meta=np.array([dataset[\"meta\"]], dtype=object),\n",
    "        )\n",
    "\n",
    "        # Linear\n",
    "        _, (_, test_acc_lin) = train_and_eval_linear(\n",
    "            dataset_path=tmp_path,\n",
    "            test_size=0.2,\n",
    "            random_state=0,\n",
    "        )\n",
    "        acc_lin.append(test_acc_lin)\n",
    "\n",
    "        # MLP\n",
    "        _, (test_acc_mlp, _) = train_rate_mlp(\n",
    "            dataset_path=tmp_path,\n",
    "            test_size=0.2,\n",
    "            random_state=0,\n",
    "            n_epochs=n_epochs_mlp,\n",
    "        )\n",
    "        acc_mlp.append(test_acc_mlp)\n",
    "\n",
    "        # SNN\n",
    "        _, (test_acc_snn, _) = train_snn_decoder(\n",
    "            dataset_path=tmp_path,\n",
    "            test_size=0.2,\n",
    "            random_state=0,\n",
    "            n_epochs=n_epochs_snn,\n",
    "        )\n",
    "        acc_snn.append(test_acc_snn)\n",
    "\n",
    "        os.remove(tmp_path)\n",
    "\n",
    "    nl_arr = np.array(noise_levels, dtype=float)\n",
    "    return nl_arr, np.array(acc_lin), np.array(acc_mlp), np.array(acc_snn)\n",
    "\n",
    "\n",
    "# === 实验 3：统一跑完三组 sweep 并画图 ===\n",
    "\n",
    "N_arr, accN_lin, accN_mlp, accN_snn = sweep_population_size()\n",
    "sigma_arr, accS_lin, accS_mlp, accS_snn = sweep_tuning_sigma()\n",
    "nl_arr, accNoise_lin, accNoise_mlp, accNoise_snn = sweep_noise_level()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# 1) Accuracy vs N\n",
    "ax = axes[0]\n",
    "ax.plot(N_arr, accN_lin,  marker=\"o\", linestyle=\"-\",  label=\"Linear\")\n",
    "ax.plot(N_arr, accN_mlp,  marker=\"s\", linestyle=\"--\", label=\"MLP (rate)\")\n",
    "ax.plot(N_arr, accN_snn,  marker=\"D\", linestyle=\"-.\", label=\"SNN (spike)\")\n",
    "ax.set_xlabel(\"Number of neurons (N)\")\n",
    "ax.set_ylabel(\"Test accuracy\")\n",
    "ax.set_title(\"Population size sweep\")\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "# 2) Accuracy vs sigma\n",
    "ax = axes[1]\n",
    "ax.plot(sigma_arr, accS_lin,  marker=\"o\", linestyle=\"-\",  label=\"Linear\")\n",
    "ax.plot(sigma_arr, accS_mlp,  marker=\"s\", linestyle=\"--\", label=\"MLP (rate)\")\n",
    "ax.plot(sigma_arr, accS_snn,  marker=\"D\", linestyle=\"-.\", label=\"SNN (spike)\")\n",
    "ax.set_xlabel(\"Tuning width σ (deg)\")\n",
    "ax.set_title(\"Tuning width sweep\")\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3) Accuracy vs noise level\n",
    "ax = axes[2]\n",
    "ax.plot(nl_arr, accNoise_lin,  marker=\"o\", linestyle=\"-\",  label=\"Linear\")\n",
    "ax.plot(nl_arr, accNoise_mlp,  marker=\"s\", linestyle=\"--\", label=\"MLP (rate)\")\n",
    "ax.plot(nl_arr, accNoise_snn,  marker=\"D\", linestyle=\"-.\", label=\"SNN (spike)\")\n",
    "ax.set_xlabel(\"Noise level (relative)\")\n",
    "ax.set_title(\"Noise sweep\")\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
